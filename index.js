const express = require("express");
const cors = require("cors");
const fetch = require("node-fetch");

const app = express();
const PORT = process.env.PORT || 3000;

app.use(cors());
app.use(express.json({ limit: "1mb" }));

app.get("/", (req, res) => res.send("RebLaw AI Proxy is running."));
app.get("/health", (req, res) => res.json({ ok: true }));

function normalizeIncoming(reqBody) {
  const body = reqBody || {};

  // Preferred: WordPress/plugin style { messages:[...], meta:{...} }
  if (Array.isArray(body.messages) && body.messages.length) {
    return {
      messages: body.messages,
      meta: body.meta || {},
    };
  }

  // Simple clients { question:"..." }
  if (typeof body.question === "string" && body.question.trim()) {
    const systemPrompt = `You are RebLaw, a professional legal assistant.
Always respond in the same language as the user (Persian/Farsi, Kurdish, or English).
If the user writes in Persian, answer fully in Persian.
If the user writes in Kurdish, answer fully in Kurdish.
If the user writes in English, answer in English.
Be clear, structured, and practical.`;

    return {
      messages: [
        { role: "system", content: systemPrompt },
        { role: "user", content: body.question.trim() },
      ],
      meta: body.meta || {},
    };
  }

  return null;
}

async function callOpenAI({ model, messages, temperature }) {
  const resp = await fetch("https://api.openai.com/v1/chat/completions", {
    method: "POST",
    headers: {
      "Content-Type": "application/json",
      Authorization: `Bearer ${process.env.OPENAI_API_KEY}`,
    },
    body: JSON.stringify({
      model,
      messages,
      temperature,
    }),
  });

  const data = await resp.json();
  return { ok: resp.ok, status: resp.status, data };
}

async function handleAsk(req, res) {
  const normalized = normalizeIncoming(req.body);

  if (!normalized) {
    return res.status(400).json({
      success: false,
      message: 'Invalid payload. Send {messages:[...]} or {question:"..."}',
    });
  }

  if (!process.env.OPENAI_API_KEY) {
    return res.status(500).json({
      success: false,
      message: "OPENAI_API_KEY is not set on the server.",
    });
  }

  // Safer default than gpt-3.5-turbo (can be overridden in Railway Variables)
  const model = process.env.OPENAI_MODEL || "gpt-4o-mini";
  const temperature = 0.2;

  try {
    const { ok, status, data } = await callOpenAI({
      model,
      messages: normalized.messages,
      temperature,
    });

    if (!ok) {
      console.error("[OpenAI] status:", status);
      console.error("[OpenAI] body:", data);
      return res.status(status).json({
        success: false,
        message: "OpenAI API error",
        details: data,
      });
    }

    const answer = data?.choices?.[0]?.message?.content?.trim();

    if (!answer) {
      console.error("[OpenAI] Missing answer field. Raw:", data);
      return res.status(502).json({
        success: false,
        message: "No answer generated by AI.",
        details: data,
      });
    }

    return res.json({ success: true, answer });
  } catch (err) {
    console.error("[Proxy] error:", err?.message || err);
    return res.status(500).json({
      success: false,
      message: "Proxy server error",
    });
  }
}

app.post("/ask", handleAsk);
app.post("/api/ask", handleAsk);

app.listen(PORT, "0.0.0.0", () => {
  console.log(`RebLaw AI Proxy listening on port ${PORT}`);
});
